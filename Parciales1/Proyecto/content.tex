% Indice
\tableofcontents
\newpage

%% Capitulo 1
\thispagestyle{empty}
\part{Ecuaciones Diferenciales Ordinarias con más de dos Variables}

En este capítulo se estudiarán conceptos básicos para la solución de ecuaciones diferenciales parciales, para lo cual se recolectan conceptos de geometría y ecuaciones diferenciales ordinarias.

\section{Superficies y Curvas en Tres Dimensiones}

Tomando una superficie en el espacio cartesiano $(x,y,z)$
	$$f(x,y,z) = 0$$
Se escoje un punto que satisface la ecuación anterior y se incrementa $(\delta x, \delta y, \delta z)$ lo que esta relacionado con la ecuación
	$$\pdv{f}{x} \delta x + \pdv{f}{y} \delta y + \pdv{f}{z} \delta z = 0$$
En otras palabras, en la vecindad de $P(x,y,z)$ existen puntos $P'(x + \xi ,y + \eta , z + \zeta)$ que satisfacen la ecuación de superficie y que para cualesquiera dos, el tercero esta dado por:
	$$\xi \pdv{f}{x} + \eta \pdv{f}{y} + \zeta \pdv{f}{z} = 0$$
	
Las ecuaciones de la forma:
	$$x = F_1 (u,v) \quad \quad y = F_2 (u,v) \quad \quad z = F_3 (u,v)$$
Son conocidas como las \textbf{Ecuaciónes Paramétricas de la Superficie.} Esto es porque tanto $u$ como $v$ pueden ser expresadas como funciones de $x$ e $y$, una vez se encuentre dichos valores, se conocerán $u$ y $v$; además, $z$ se encuentra sustituyendo lo encontrado anteriormente en su ecuación, con esto, es claro que cumplen con la ecuación de superficie. \\

Cabe recalcar que varios conjuntos de ecucaciones paramétricas generan las mismas superficies, vease:
	$$(a\sin{u} \cos{v} , a\sin{u} \cos{v} ,a\cos{u})$$
Y 
	$$\qty(a\frac{1 - v^2}{1 + v^2} \cos{u} , a\frac{1 - v^2}{1 + v^2} \sin{u} ,\frac{2av}{1 + v^2})$$

Generan la superficie esférica
	$$x^2 + y^2 + z^2 = a^2$$
	
Las superficies pueden ser previstas como una curva, siempre y cuando cumplan con las ecuaciones de la superficie y esten en el plano $z = k$. Lo que significa que $(x,y,z)$ esta en la curva $\Gamma _k$.

Tomando como ejemplo:

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.45]{Images/surfaceSection1.jpeg}
	\caption{Ejemplo de Curva en Superficie}
	\label{curveSurface}
\end{figure}

Esta idea puede ser facilmente generalizada simplemente tomando dos superficies que se intersectan, la curva de intersección es el análogo de $\Gamma _k$ en el ejemplo anterior. Esta idea esta representada en la "Figure 2" de \ref{curveSurface}. Matemáticamente hablando, la curva $C$ es conformada por todos aquellos puntos que cumplen las ecuaciones de ambas superficies:
	$$f(x,y,z) = 0 \quad \quad g(x,y,z) = 0$$
Dicha curva se puede representar por medio de sus ecuaciones paramétricas. Ahora, suponiendo que la curva $C$ esta sobre la superficie cuya ecuación es:
	$$F(x(t),y(t),z(t)) = 0$$
Derivando $F$ se tienen la relación:
	$$\pdv{F}{x} \dv{x}{t} + \pdv{F}{y} \dv{y}{t} + \pdv{F}{z} \dv{z}{t} = 0$$
De modo que la tangente a la curva es:
	$$\qty(\pdv{F}{x} , \pdv{F}{y} , \pdv{F}{z})$$
	
La ecuación del plano $\pi _1$ en el punto $P(x,y,z)$ y la superficie $S_1$ es:
	$$(X - x)\pdv{F}{x} + (Y - y)\pdv{F}{y} + (Z - z)\pdv{F}{z} = 0$$
Con $(X,Y,Z)$ es cualquier otro punto en el plano. Realizando lo mismo para la superficie $S_2$. Se tiene:
	$$(X - x)\pdv{G}{x} + (Y - y)\pdv{G}{y} + (Z - z)\pdv{G}{z} = 0$$
Y la intersección $L$ de los planos $\pi _1$ y $\pi _2$ en $P$ es tangente a la curva $C$. \\

Para visualizarlo de mejor manera, se tiene la siguiente figura:

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{Images/planesSection1.jpeg}
	\caption{Visualización de la Recta Tangente a la Curva}
	\label{planes}
\end{figure}

De las ecuaciones de los planos se tiene que las ecuaciones de la recta $L$ son:
	$$\frac{X - x}{\pdv{F}{y} \pdv{G}{z} - \pdv{F}{z} \pdv{G}{y}} = \frac{Y - y}{\pdv{F}{z} \pdv{G}{x} - \pdv{F}{x} \pdv{G}{z}} = \frac{Z - z}{\pdv{F}{x} \pdv{G}{y} - \pdv{F}{y} \pdv{G}{x}}$$

En otras palabras, las razones de dirección de la recta $L$ son:
	$$\Bigg\{ \pdv{(F,G)}{(y,z)} , \pdv{(F,G)}{(z,x)} , \pdv{(F,G)}{(x,y)} \Bigg\}$$


\subsection{Problemas Resueltos}


\section{Ecuaciones Diferenciales de Primer Orden y Primer Grado de Tres Variables}

Un ejemplo claro de sistema de ecuaciones simultaneas de primer orden y primer grado es:
	$$\dv{x_i}{t} = f_i (x_1 ,\ldots ,x_n ,t)$$
aparece frecuentemente en física. Otro ejemplo claro, es el Hamiltoniano de un sistema en movimiento con $n$ grados de libertad tiene la forma:
	$$\dv{p_i}{t} = -\pdv{H}{q_i} \quad \quad \dv{q_i}{t} = \pdv{H}{p_i} \quad \quad i = 1,\ldots ,n$$
Donde $H(q_1,\ldots ,q_n ,p_1,\ldots ,p_n ,t)$ es el Hamiltoneano del sistema. Para un sistema de un grado de libertad se tiene:
	$$\dv{p}{t} = -\pdv{H}{q} \quad \quad \dv{q}{t} = \pdv{H}{p}$$
Si se tiene:	
	$$-\pdv{H}{q} = \frac{P(p,q,t)}{R(p,q,t)} \quad \quad \pdv{H}{p} = \frac{Q(p,q,t)}{R(p,q,t)}$$
La ecuación anterior se puede colocar de la forma:
	$$\frac{\dd{p}}{P(p,q,t)} = \frac{\dd{q}}{Q(p,q,t)} = \frac{\dd{t}}{R(p,q,t)}$$
Dado esto, la ecuación anterior se puede expresar de una forma general, teniendo $P,Q,R$ funciones de $x,y,z$, entonces se tiene:

\begin{align}
	\frac{\dd{x}}{P} = \frac{\dd{y}}{Q} = \frac{\dd{z}}{R} \label{formaPQR}
\end{align}

Para asegurar la unicidad de la ecuación se tiene el siguiente teorema:

\begin{teorema} \tt
	Si las funciones $f_1 (x,y,z)$ y $f_2 (x,y,z)$ son continuas en una región definida por $\abs{x - a} < k$, $\abs{y - b} < l$, $\abs{z - c} < m$ y si en dicha región las funciones satisfacen una condición Lipschitz del tipo:
		$$\abs{f_1 (x,y,z) - f_1 (x,\eta ,\zeta)} \leq A_1 \abs{y - \eta} + B_1 \abs{z - \zeta}$$
		$$\abs{f_2 (x,y,z) + f_2 (x,\eta ,\zeta)} \leq A_2 \abs{y - \eta} + B_2 \abs{z - \zeta}$$
	en un intervalo adecuado $\abs{x - a} < h$ existe un único par de funciones $y(x)$ y $z(x)$ continuas y con derivadas continuas en dicho intervalo, que satisfacen las siguientes ecuaciones diferenciales:
		$$\dv{y}{x} = f_1 \quad \quad \dv{z}{x} = f_2$$
	y que tienen la propiedad de $y(a) = b$, $z(a) = c$ donde $a,b,c$ son arbitrarios.
\end{teorema}

No se demostrará este teorema, para una demostración formal consulte el siguiente libro de análisis\footnote{E. Goursat, "A Course in Mathematical Analysis" (Ginn, Boston, 1917), vol. II, pt. II, pp. 45ff.}. \\

El resultado del teorema se muestra en la figura \ref{teorem1Figure}. En base al teorema, existe un cilindro $y = y(x)$ pasando por el punto $(a,b,0)$, y un cilindro $z = z(x)$ pasando por le punto $(a,0,c)$, tales que $\dv{y}{x} = f_1$ y $\dv{z}{x} = f_2$. La solución completa del par de ecuaciones consiste en un conjunto de puntos en común con los cilindros, es decir, la curva de intersección $\Gamma$.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.15]{Images/teorem1Figure.jpeg}
	\caption{Visualización del Teorema $1$}
	\label{teorem1Figure}
\end{figure}

De esto se concluye que, la solución general del conjunto de ecuaciones del tipo \eqref{formaPQR} será una familia de curvas de dos parámetros.

\section{Métodos de Solución de $\flatfrac{\dd{x}}{P} = \flatfrac{\dd{y}}{Q} = \flatfrac{\dd{z}}{R}$}


De la sección anterior se tiene:
	$$\frac{\dd{x}}{P} = \frac{\dd{y}}{Q} = \frac{\dd{z}}{R}$$
Si se pueden derivar dos relaciones de la forma:
	$$u_1 (x,y,z) = c_1 \quad \quad u_2 (x,y,z) = c_2$$
Variando esas constantes, se obtiene la familia de curvas que satisfacen la ecuación. \\

\textit{Método (a): } Para encontrar las funciones $u_1$ y $u_2$ se puede observar que cualquier dirección tangencial por un punto $(x,y,z)$ a una superficie $u_1 = c_1$ satisface la relación:
	$$\pdv{u_1}{x} \dd{x} + \pdv{u_1}{y} \dd{y} + \pdv{u_1}{z} \dd{z} = 0$$

Si $u_1 = c_1$ es un sistema adecuado de superficies, la dirección tangencial a la curva de integral por el punto $(x,y,z)$ si también es una dirección tangencial a esta superficie. De esto:
	$$P\pdv{u_1}{x} + Q\pdv{u_1}{y} + R\pdv{u_1}{z} = 0$$
Para encontrar $u_1$, y similarmente $u_2$, se intenta encontrar funciones $P'$, $Q'$ y $R'$ tales que:
	\begin{align}
		PP' + QQ' + RR' = 0 \label{PPQQRR}
	\end{align}
Y, además, existe una función $u_1$ con las propiedades:
	$$P' = \pdv{u_1}{x}, \quad \quad Q' = \pdv{u_1}{y},\quad \quad R' = \pdv{u_1}{z}$$
Lo que implica que:
	$$P' \dd{x} + Q'\dd{y} + R'\dd{z}$$
Es una diferencial exacta de $\dd{u_1}$. Se tomará el ejemplo $2$ del libro (Sección $3$, capítulo $1$, pp. 11.)

%\begin{ejemplo} \slshape
%	Encuentre las curvas de integral de las ecuaciones:
%		$$\frac{\dd{x}}{y(x + y) + az} = \frac{\dd{y}}{x(x + y) - az} = \frac{\dd{z}}{z(x + y)}$$
%	En este caso se tiene:
%		$$P = y(x + y) + az \quad \quad Q = x(x + y) - az \quad \quad R = z(x + y) $$
%	Tomando
%		$$P' = \frac{1}{z} \quad \quad Q' = \frac{1}{z} \quad \quad R' = -\frac{x + y}{z^2}$$
%	La condición \eqref{PPQQRR} se satisface, entonces:
%		$$u_1 = \frac{x + y}{z}$$
%	Similarmente, si se toma:
%		$$P' = x \quad \quad Q' = -y \quad \quad R' = -a$$
%	la condición \eqref{PPQQRR} se satisface, la función correspondiente:
%		$$u_2 = \frac{1}{2} (x^2 - y^2) - az$$
%	De modo que las curvas de integral para las ecuaciones diferenciales son la familia de dos parámetros:	
%		$$x + y = c_1 z \quad \quad x^2 - y^2 - 2az = c_2$$
%\end{ejemplo}



\textit{Método (b): } Suponga que se pueden encontrar tres funciones $P',Q',R'$ tal que:
	$$\frac{P' \dd{x} + Q' \dd{y} + R'\dd{z}}{PP' + QQ' + RR'}$$
Es un diferencial exacto $\dd{W'}$, y si se pueden encontrar otras tres funciones $P'',Q'',R''$ tales que:
	$$\frac{P'' \dd{x} + Q'' \dd{y} + R''\dd{z}}{PP'' + QQ'' + RR''}$$
El cual es un diferencial exacto $\dd{W''}$. De esto, se sabe que:
	$$\dd{W'} = \dd{W''}$$
De lo que se deriva.
	$$W' = W'' + c_1$$
Donde $c_1$ es una constante arbitraria. \\


%\begin{ejemplo} \slshape
%	Utilizando el método \textit{(b)}, se resuelven las ecuaciones:
%		$$\frac{\dd{x}}{y + \alpha z} = \frac{\d{y}}{z + \beta x} = \frac{\dd{z}}{x + \gamma y}$$
%	Reescribiendo la ecuación como en el método se tiene
%		$$\frac{\lambda \dd{x} + \mu \dd{y} + \nu \dd{z}}{\lambda (y + \alpha z) + \mu (z + \beta x) + \nu (x + \gamma y)}$$
%	Con las constantes añadidas, la expresión es un diferencial exacto si es de la forma:
%		$$\frac{1}{\rho} \frac{\lambda \dd{x} + \mu \dd{y} + \nu \dd{z}}{\lambda x + \mu y + \nu z}$$
%	Lo que es posible solo si
%		$$\left.\begin{array}{c}
%			-\rho \lambda + \beta \mu + \nu = 0 \\
%			\lambda - \rho \mu + \gamma \nu = 0 \\
%			\alpha \lambda + \mu - \rho \nu = 0 
%		\end{array}\right\}
%		$$
%	Estas ecuaciones tienen solucion solo si $\rho$ es solución de la ecuación:
%		$$\rho ^3 + (\alpha + \beta + \gamma) \rho + \alpha \beta \gamma + 1 = 0$$
%	Las raíces de la ecuación se denotarán como $\rho _1,  \rho _2,\rho _3$, sustituyendo $\rho _1$ en la relación 
%\end{ejemplo}

\textit{Método (c): } Cuando una de las variables es ausente de las ecuaciones iniciales, se pueden encontrar las curvas integral en una manera sencilla. 
	$$\frac{\dd{y}}{Q} = \frac{\dd{z}}{R}$$
Puede ser descrito en la forma
	$$\dv{y}{z} = f(y,z)$$
De las EDOs esta ecuación tiene solución de la forma:
	$$\phi (y,z,c_1) = 0$$
Resolviendo la ecuación para $z$ y sustituyendolo se obtiene
	$$\dv{y}{x} = g(x,y,c_1)$$
Lo que tiene solución:
	$$\psi (x,y,c_1 ,c_2) = 0$$

%\begin{ejemplo} \slshape
%	Encuentre las curvas integral de las ecuaciones:
%		$$\frac{\dd{x}}{x + z} = \frac{\dd{y}}{y} = \frac{\dd{z}}{z + y^2}$$
%	Tomando las ultimas dos, se tiene:
%		$$\dv{z}{y} - \frac{z}{y} = y \quad \quad \Rightarrow \quad \quad \dv{y} \qty(\frac{z}{y}) = 1$$
%	Lo que tiene una solución $\boxed{z = c_1 y + y^2}$. Ahora tomando las primeras dos ecuaciones:
%		$$\dv{x}{y} = \frac{x}{y} + \frac{z}{y}$$
%	Sustituyendo, reduciendo y resolviendo la ED, se tiene:
%		$$\boxed{x = c_1 y \ln{y} + c_2 y + y^2}$$
%	Las ecuaciones encerradas son las curvas integrales de las ecuaciones propuestas.
%\end{ejemplo}



\section{Trayectorias Ortogonales de un Sistema de Curvas en una Superficie}

Este problema es muy conocido, para 3 dimensiones: sea una superficie:
	$$F(x,y,z) = 0$$
Se considera un conjunto de curvas en las cuales la superficie se encuentra, tomando un nuevo conjuto de curvas las cuales cortan a todas las curvas del otro conjunto en un ángulo de $90$ grados. Este nuevo sistema de curvas es llamado el sistema de \textit{trayectorias ortogonales} del conjunto de curvas dado. \\

En general, el sistema de curvas se puede representar como las intersecciones de la familia de superficies
	$$G(x,y,z) = c_1$$
Con la superficie dada. \\

En caso general, la dirección tangencial $(\dd{x} ,\dd{y} \dd{z})$ a la curva dada en el punto $(x,y,z)$ en la superficie $F$, satisface las ecuaciones:
	$$\pdv{F}{x} \dd{x} + \pdv{F}{y} \dd{y} + \pdv{F}{z} \dd{z} = 0$$
y
	$$\pdv{G}{x} \dd{x} + \pdv{G}{y} \dd{y} + \pdv{G}{z} \dd{z} = 0$$
Los trios deben cumplir:
	$$\frac{\dd{x}}{P} = \frac{\dd{y}}{Q} = \frac{\dd{z}}{R}$$
Donde
	$$(P,Q,R) = \qty(\pdv{(F,G)}{(y,z)} , \pdv{(F,G)}{(z,x)} , \pdv{(F,G)}{(x,y)})$$
Para el sistema ortogonal se tienen las siguiente dirección tangencial $(\dd{x'} ,\dd{y'} ,\dd{z'})$ que estan en la superficie $F$, tal que:
	$$\pdv{F}{x} \dd{x'} + \pdv{F}{y} \dd{y'} + \pdv{F}{z} \dd{z'} = 0$$

El cual es perpendicular al sistema de curvas original, de la relación anterior se tiene:
	$$P\dd{x'} + Q\dd{y'} + R\dd{z'} = 0$$
Y de las últimas dos ecuaciones se tiene
	$$\frac{\dd{x'}}{P'} = \frac{\dd{y'}}{Q'} = \frac{\dd{z'}}{R'}$$
Donde:
	$$P' = R\pdv{F}{y} - Q\pdv{F}{z}$$
	$$P' = P\pdv{F}{z} - R\pdv{F}{x}$$
	$$P' = Q\pdv{F}{x} - P\pdv{F}{y}$$

La solucion del sistema primado y la relación $F$ da el sistema de trayectorias ortogonales.

\section{Formas Diferenciales y Ecuaciones Pfaffianas}

\begin{definicion}
	Sea $F_i$ ($i = 1,\ldots ,n$) son funciones de una o todas las $n$ variables independientes, la relación:
		$$\sum _{i=1} ^{n} F_i \dd{x_i} = 0$$
	Es llamada \textbf{Ecuación Diferencial Pfaffiana}.
\end{definicion}

Para una ecuación Pfaffiana de dos variables $P\dd{x} + Q\dd{y} = 0$, puede ser descrita en una forma como $\dd{\phi}$ con $\phi = c$, en este caso se dice que la ecuación es \textit{exacta} o \textit{integrable.} Incluso sino es exacta se escribe la ecuación de la forma:
	$$\pdv{\phi}{x} \dd{x} + \pdv{\phi}{y} \dd{y} = 0$$
Existen $\phi$ y $\mu$ tales que:
	$$\frac{1}{P} \pdv{\phi}{x} = \frac{1}{Q} \pdv{\phi}{y} = \mu$$
A $\mu$ se le conoce como el factor integrante de la ecuación diferencial Pfaffiana.

\begin{teorema} \tt
	Una ecuación diferencial Pfaffiana en dos variables siempre posee un factor integrante.
\end{teorema}



\begin{teorema} \tt
	Una condición necesaria y suficiente que existen entre dos funciones $u(x,y)$ y $v(x,y)$ una relación $F(u,v) = 0$, que no envuelve $x$ o $y$ es que:
		$$\frac{\partial (u,v)}{\partial (x,y)} = 0$$
\end{teorema}



\begin{teorema} \tt
	Si $\vb{X}$ es un vectortal que $\vb{X} \cdot \curl{\vb{X}}$ y $\mu$ es una función arbitraria de $x,y,z$, entonces $(\mu \vb{X})\cdot \curl{(\mu \vb{X})} = 0$.
\end{teorema}

Como no todas las funciones de esta forma poseen integrales de la forma $\mu (x,y,z)$.

\begin{teorema} \tt
	Una condicion suficiente y necesaria para que la ecuación Pfaffiana $\vb{X} \cdot \dd{\vb{r}} = 0$ sea integrable es que $\vb{X} \cdot \curl{\vb{X}} = 0$.
\end{teorema}

\dsnote{En la siguiente sección se estudiarán los métodos de solución de ecuaciones Pfaffianas.}

\begin{teorema} \tt
	Dado un factor integrante de la ED Pfaffiana:
		$$X_1 \dd{x_1} + X_2 \dd{x_2} + \cdots + X_n \dd{x_n} = 0$$
	Se pueden encontrar un número infinito de ellos.
\end{teorema}





\section{Solución a Ecuaciones Diferenciales Pfaffianas en Tres Variables}

\section{Teorema de Carathéodory}

\section{Aplicaciones a Termodinámica}


\newpage
% CAPITULO 2
\part{Ecuaciones Diferenciales Parciales de Primer Orden}

\section{Ecuaciones Diferenciales Parciales}

Ahora se estudiarán las ecuaciones diferenciales parciales, tales como las que aparecen en la física. Por ejemplo, la temperatura de un cuerpo, depende de la posición en el espacio y del instante del tiempo, de modo que, una relación obtenida para este fenómeno físico es:
	$$F\qty(\pdv{\theta}{x} ,\ldots ,\pdv[2]{\theta}{x} ,\ldots ,\pdv[2]{\theta}{x}{t}, \ldots) = 0$$

A esto se le conoce como una ecuación diferencial parcial.




\section{Origenes de las Ecuaciones Diferenciales Parciales de Primer Orden}


Antes de discutir los métodos de solución, es importante estudiar de donde vienen y como surgieron. Estas surgieron de problemas geométricos, las identidades geométricas pueden ser representadas por medio de soluciones de ecuaciones diferenciales parciales. Muchas relaciones pueden ser escritas en la forma:
	$$F(x,y,z,a,b) = 0$$
De modo que, al derivarlas se obtiene:
	$$\pdv{F}{x} + p\pdv{F}{z} = 0 \quad \quad \quad \pdv{F}{y} + q\pdv{F}{z} = 0$$

Lo que implica que una supeficie, o sistema de superficies, da inicio a las EDP de primer orden. Eliminando $a$ y $b$ llegando a una relación del tipo $f(x,y,z,p,q) = 0$. Partiendo de una función general
	$$F(u,v) = 0,$$
donde $u$ y $v$, son funciones de las tres variables $x,y,z$. Derivando la ecuación propuesta respecto a $x$ e $y$, se obtienen las siguientes ecuaciones
\begin{align*}
	\pdv{F}{u} \qty[\pdv{u}{x} + p\pdv{u}{z}] + \pdv{F}{v} \qty[\pdv{v}{x} + p \pdv{v}{z}] &= 0 \\
	\pdv{F}{u} \qty[\pdv{u}{y} + q\pdv{u}{z}] + \pdv{F}{v} \qty[\pdv{v}{y} + q\pdv{v}{z}] &= 0.
\end{align*}

Eliminando $\pdv{F}{u}$ y $\pdv{F}{v}$, se obtiene
$$p\pdv{(u,v)}{(y,z)} + q\pdv{(u,v)}{(z,x)} = \pdv{(u,v)}{(x,y)},$$
que es una EDP del tipo $f(x,y,z,p,q) = 0$.

\subsection{Problemas}



\section{Problema de Cauchy para Ecuaciones de Primer Orden}
En la teoría de ecuaciones diferenciales es necesario tener un teorema que confirme la existencia de la solución para una EDP; además, de otro que implique la unicidad de dicha solución. Para las EDPs de primer orden se tienen definidas las condiciones para que se de esto, en el \textit{problema de Cauchy}. \\

\textit{Problema de Cauchy:} \\
\begin{itemize}
	\item Si $x_o (\mu)$, $y_o (\mu)$ y $z_o (\mu)$ son funciones tales que sus primeras derivadas con continuas en el intervalo definido por $\mu _1 < \mu < \mu _2$.
	\item Y si $F(x,y,z,p,q)$ es una función continua de $x,y,z,p,q$ en una región específica $U$ en el espacio $xyzpq$, entonces, es necesario establecer la exisstencia de una función $\phi (x,y)$ con las siguientes propiedades
	\begin{enumerate}
		\item $\phi (x,y)$ y sus primeras derivadas parciales son continuas en $R$.
		\item Para todos los valores de $x$ y $y$ en la región en la que las primeras derivadas son continuas, el punto $(x,y,\phi (x,y),\phi _x (x,y), \phi _y (x,y))$ esta en $U$ y 
		$$F(x,y,\phi (x,y),\phi _x (x,y), \phi _y (x,y)) = 0.$$
		\item para todo $\mu$ en el intervalo, el punto $(x_o (\mu), y_o (\mu))$ esta en $R$, y 
		$$\phi (x_o (\mu), y_o (\mu)) = z_o$$
	\end{enumerate}
\end{itemize}

Lo que se espera demostrar geométricamente es que existe una superficie $\phi (x,y) = z$ que pasa por la curva $\Gamma$ cuyas ecuaciones paramétricas son
	$$x = x_o (\mu) \quad \quad y = y_o (\mu) \quad \quad z = z_o (\mu).$$	

No se demostrará este teorema de existencia, se creerá por fé. Teorema de Sonia Kowalewski.

\begin{teorema}
	Si $g(y)$ y todas sus derivadas son continuas para $\abs{y - y_o} < \delta$, si $x_o$ es un número dado y $z_o = g(y_o),q_o = g'(y_o)$, y si $f(x,y,z,q)$ y  todas sus derivadas parciales son continuas en una región definida por
	$$\abs{x - x_o} < \delta \quad \quad \abs{y - y_o} < \delta \quad \quad \abs{z - z_o} < \delta ,$$
existe una única función $\phi (x,y)$ tal que:
\begin{enumerate}[a)]
	\item $\phi (x,y)$ y todas sus derivadas parciales continuas en una región $R$ definida por $\abs{x - x_o} < \delta _1$, $\abs{y - y_o} < \delta _2$.
	\item Para todo $(x,y)$ en $R$, $z = \phi (x,y)$ es una solución de la ecuación
	$$\pdv{z}{x} = f\qty(x,y,z,\pdv{z}{y})$$
	\item Para todos los valores de $y$ en el intervalo $\abs{y - y_o} < \delta _1$, $\phi (x_o ,y) = g(y)$.
\end{enumerate}
\end{teorema}

\section{Ecuaciones Lineales de Primer Orden}

Ya se discutieron ecuaciones lineales de la forma
	$$P\pdv{z}{x} + Q\pdv{z}{y} = R,$$
donde $P,Q,R$ son funciones de $x,y,z$. El precursor en esta teoreia fue lagrange, de modo que es comunmente llamada a la ecuación anterior, la ecuación de Lagrange. Generalizado a $n$ variables independientes
	$$X_1 \pdv{f}{x_1} + \cdots + X_n \pdv{f}{x_n} = Y,$$
donde cada $X_i$ e $Y$ son funciones de $n$ variables independientes $x_i$, $i = 0,\ldots ,n$.

\begin{teorema}
	La solución general de la EDP
		$$P\pdv{z}{x} + Q\pdv{z}{y} = R,$$
	es
		$$F(u,v) = 0,$$
	donde $F$ es una solución arbitraria y $u(x,y,z) = c_1$ y $v(x,y,z) = c_2$ forman solución a las ecuaciones
		$$\frac{\dd{x}}{P} = \frac{\dd{y}}{Q} = \frac{\dd{z}}{R}.$$
\end{teorema}

La generalización del teorema es:

\begin{teorema}
	Si $u_i (x_1 ,x_2 ,\ldots x_n ,z) = c_i$ para $i = 1 ,\ldots ,n$ son soluciones independientes de las ecuaciones
	$$\frac{\dd{x_1}}{P_1} = \cdots = \frac{\dd{x_n}}{P_n} = \frac{\dd{z}}{R},$$
	entonces la relación $\Phi (u_1 ,\ldots , u_n) = 0$, en donde la función $\Phi$ es arbitraria, es una solución general de la EDP lineal
	$$P_1 \pdv{z}{x_1} + \cdots + P_n \pdv{z}{x_n} = R.$$
\end{teorema}


\section{Superficies Integrales}

De lo visto en la sección anterior, suponemos que de la ecuación se encontraron dos soluciones
	$$f(x,y,z) = c_1, \quad \quad v(x,y,z) = c_2.$$
Además, se sabe que cualquier solución de una ecuación lineal es de la forma
	$$F(u,v) = 0,$$
el problema a tratar es encontrar la función $F$ para casos especiales. Para encontrar la superficie integral que pase por la curva $\Gamma$ cuyas ecuaciones paramétricas son
	$$x = x(t) \quad y = y(t) \quad z = z(t),$$ 
entonces, la solución partícular debe cumplir
	$$u(x(t),y(t),z(t)), \quad \quad v(x(t),y(t),z(t)).$$


\newpage
% CAPITULO 3
\part{Ecuaciones Diferenciales Parciales de Segundo Orden}


\section{Origen de Ecuaciones de Segundo Orden}

Suponiendo una función del tipo
	$$z = f(u) + g(v) + w$$
las derivadas son de la forma
	
\begin{align*}
	p &= \pdv{z}{x} = f'(u) u_x + g'(v) v_x + w_x \\
	q &= \pdv{z}{y} = f'(u) u_y + g'(v) v_y + w_y \\
	r &= \pdv[2]{z}{x} = f''(u) u_x ^2 + g''(v) v_x ^2 + f'(u) u_{xx} g'(v) v_{xx} + w_{xx} \\
	s &= \pdv[2]{z}{x}{y} = f''(u) u_x u_y + g''(v) v_x u_y + f'(u) u_{xy} + g'(v) v_{xy} + w_{xy} \\
	t &= \pdv[2]{z}{y} = f''(u) u_y ^2 + g''(v) v_y ^2 + f'(u) u_{yy} g'(v) v_{yy} + w_{yy}
\end{align*}


eliminando las perimeras y segundas derivadas de las funciones $f$ y $g$, se tiene:
\begin{align*}
	\left|\begin{array}{ccccc}
		p-w_x & u_x & v_x & 0 & 0 \\
		q-w_y & u_y & v_y & 0 & 0 \\
		r-w_{xx} & u_{xx} & v_{xx}  & u_x ^2 & v_x ^2 \\
		s-w_{xy} & u_{xy} & v_{xy}  & u_x u_y & v_x v_y \\
		t-w_{yy} & u_{yy} & v_{yy}  & u_y ^2 & v_y ^2 
	\end{array}\right|
	= 0,
\end{align*}

expandiendo el determinante en términos de la primera columna, se tiene la siguiente relación
	$$Rr + Ss + Tt + Pp + Q = W.$$
Donde las letras mayusculas representan funciones de $x,y,z$.

\section{Ecuaciones Diferenciales Parciales Lineales con Coeficientes Constantes}

\section{Ecuaciones con Coeficientes Variables}

\section{Separación de Variables}




























































